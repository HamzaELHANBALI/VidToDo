# VidToDo - Project Architecture Documentation

## üìê System Overview

**VidToDo** (YouTube Action Extractor) is a Streamlit-based web application that transforms YouTube tutorial videos into actionable step-by-step guides. The system extracts transcripts from YouTube videos, uses AI to analyze them, and presents structured, actionable steps with timestamps, code snippets, and summaries.

---

## üèóÔ∏è High-Level Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         USER INTERFACE                          ‚îÇ
‚îÇ                    (Streamlit Web Application)                  ‚îÇ
‚îÇ                         (app.py)                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚îÇ User Input: YouTube URL
                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    URL PROCESSING LAYER                         ‚îÇ
‚îÇ              (utils/transcript.py - extract_video_id)           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚îÇ Video ID
                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    CACHING LAYER                                ‚îÇ
‚îÇ              (Dual Cache System)                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
‚îÇ  ‚îÇ  Streamlit Cache     ‚îÇ  ‚îÇ  File-Based Cache    ‚îÇ           ‚îÇ
‚îÇ  ‚îÇ  (In-Memory, TTL)    ‚îÇ  ‚îÇ  (Persistent, TTL)   ‚îÇ           ‚îÇ
‚îÇ  ‚îÇ  (utils/cache.py)    ‚îÇ  ‚îÇ  (utils/cache.py)    ‚îÇ           ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚îÇ Cache Miss ‚Üí Fetch
                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              TRANSCRIPT EXTRACTION LAYER                        ‚îÇ
‚îÇ              (utils/transcript.py - get_transcript)             ‚îÇ
‚îÇ                    YouTube Transcript API                       ‚îÇ
‚îÇ              (youtube-transcript-api library)                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚îÇ Raw Transcript Text
                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    CACHING LAYER                                ‚îÇ
‚îÇ              (Store Transcript in Cache)                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚îÇ Transcript
                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              AI ANALYSIS LAYER                                  ‚îÇ
‚îÇ              (utils/openai_api.py)                              ‚îÇ
‚îÇ                    OpenAI GPT-4o-mini API                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ  Action Extraction     ‚îÇ  ‚îÇ  Summary Generation    ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  (JSON Format)         ‚îÇ  ‚îÇ  (Text Format)         ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚îÇ Actions JSON + Summary
                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    CACHING LAYER                                ‚îÇ
‚îÇ              (Store Analysis in Cache)                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚îÇ Cached/New Results
                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              FORMATTING & PARSING LAYER                         ‚îÇ
‚îÇ              (utils/format.py - parse_actions_json)             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚îÇ Parsed Steps + Summary
                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    PRESENTATION LAYER                           ‚îÇ
‚îÇ                    (app.py - UI Rendering)                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ  ‚îÇ   Summary    ‚îÇ  ‚îÇ    Steps     ‚îÇ  ‚îÇ    Tools     ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ    Card      ‚îÇ  ‚îÇ    Cards     ‚îÇ  ‚îÇ    Section   ‚îÇ         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîß Component Breakdown

### 1. **Frontend/UI Layer** (`app.py`)

**Purpose**: Main entry point and user interface orchestration

**Responsibilities**:
- Streamlit web application setup and configuration
- User input handling (YouTube URL)
- UI rendering and styling (custom CSS)
- Component orchestration and data flow management
- Error handling and user feedback
- Display of results (summary, steps, tools, metrics)

**Key Functions**:
- `get_cached_transcript(video_id)`: Wraps transcript fetching with dual caching
- `get_cached_analysis(video_id, transcript)`: Wraps AI analysis with dual caching

**Dependencies**:
- `utils.transcript` - For video ID extraction and transcript fetching
- `utils.openai_api` - For AI analysis
- `utils.format` - For parsing JSON results
- `utils.cache` - For persistent caching

**Interactions**:
- Receives user input (YouTube URL)
- Calls `extract_video_id()` to parse URL
- Calls `get_cached_transcript()` which internally uses `get_transcript()`
- Calls `get_cached_analysis()` which internally uses `extract_actions_and_summary()`
- Calls `parse_actions_json()` to format results
- Renders all results in the UI

---

### 2. **Transcript Extraction Module** (`utils/transcript.py`)

**Purpose**: Extract video transcripts from YouTube

**Responsibilities**:
- Extract video ID from various YouTube URL formats
- Fetch transcript from YouTube using `youtube-transcript-api`
- Handle multiple languages (French, English with fallback)
- Comprehensive error handling for YouTube API issues

**Key Functions**:

#### `extract_video_id(video_url: str) -> str`
- **Input**: YouTube URL (full URL or video ID)
- **Output**: Extracted video ID string
- **Logic**: 
  - Handles `youtube.com/watch?v=VIDEO_ID` format
  - Handles `youtu.be/VIDEO_ID` format
  - Handles direct video ID input
- **Returns**: Clean video ID

#### `get_transcript(video_url: str) -> str`
- **Input**: YouTube URL or video ID
- **Output**: Transcript text or error message string
- **Logic**:
  1. Extracts video ID using `extract_video_id()`
  2. Calls `YouTubeTranscriptApi.fetch()` with language preference (fr, en)
  3. Processes transcript data into plain text
  4. Handles various error cases (disabled transcripts, unavailable videos, IP blocks, etc.)
- **Error Handling**: Returns descriptive error messages for:
  - `TranscriptsDisabled`: Transcripts not available
  - `NoTranscriptFound`: No captions available
  - `VideoUnavailable`: Invalid video URL
  - `IpBlocked` / `RequestBlocked`: YouTube IP blocking
  - `YouTubeRequestFailed`: General API failures

**Dependencies**:
- `youtube-transcript-api` library
- YouTube's transcript service (external API)

**Interactions**:
- Called by `app.py` via `get_cached_transcript()`
- Communicates with YouTube's transcript API
- Returns transcript text or error messages to caller

---

### 3. **AI Analysis Module** (`utils/openai_api.py`)

**Purpose**: Analyze transcripts using OpenAI API to extract actionable steps and generate summaries

**Responsibilities**:
- Manage OpenAI API client initialization
- Handle API key retrieval from Streamlit secrets or environment variables
- Extract actionable steps from transcripts
- Generate video summaries
- Format responses as JSON and text

**Key Functions**:

#### `get_openai_api_key() -> str`
- **Purpose**: Retrieve API key from multiple sources
- **Priority**:
  1. Streamlit secrets (`st.secrets["OPENAI_API_KEY"]`) - for cloud deployment
  2. Environment variable (`os.getenv("OPENAI_API_KEY")`) - for local development
- **Returns**: API key string or raises error if not found

#### `get_openai_client() -> OpenAI`
- **Purpose**: Initialize OpenAI client with proper API key
- **Returns**: Configured OpenAI client instance
- **Error Handling**: Raises `ValueError` if API key not found

#### `extract_actions_and_summary(transcript: str) -> tuple[str, str]`
- **Input**: Full transcript text
- **Output**: Tuple of (actions_json_string, summary_string)
- **Process**:
  1. **Transcript Truncation**: Limits transcript to 10,000 characters for action extraction
  2. **Action Extraction**:
     - Creates detailed prompt for GPT-4o-mini
     - Requests JSON format response
     - Extracts: steps (with timestamps, code, tool_context), tools (with purpose, context, usage)
  3. **Summary Generation**:
     - Uses first 4,000 characters of transcript
     - Requests 3 bullet points, max 120 words
  4. **API Calls**: Makes two separate API calls:
     - `client.chat.completions.create()` for actions (JSON mode)
     - `client.chat.completions.create()` for summary (text mode)
- **Returns**: `(actions_json_string, summary_string)`

**Dependencies**:
- `openai` library
- `python-dotenv` for environment variable loading
- `streamlit` (for secrets access)
- OpenAI API service (external)

**Interactions**:
- Called by `app.py` via `get_cached_analysis()`
- Communicates with OpenAI GPT-4o-mini API
- Returns structured JSON (actions) and text (summary) to caller

---

### 4. **Formatting Module** (`utils/format.py`)

**Purpose**: Parse and format AI-generated JSON responses

**Responsibilities**:
- Parse JSON strings into Python dictionaries
- Extract steps from structured JSON
- Format timestamps (if needed in future)

**Key Functions**:

#### `parse_actions_json(actions_json_string: str) -> List[Dict[str, Any]]`
- **Input**: JSON string containing actions
- **Output**: List of step dictionaries
- **Logic**:
  1. Parses JSON string using `json.loads()`
  2. Extracts `steps` array from JSON structure
  3. Handles edge cases (direct list, missing steps key)
  4. Returns empty list on parse errors
- **Returns**: List of dictionaries, each containing:
  - `step`: Action description
  - `timestamp`: Time in video (mm:ss format)
  - `code`: Optional code snippet
  - `tool_context`: Optional tool usage explanation

#### `format_timestamp(seconds: float) -> str`
- **Purpose**: Convert seconds to mm:ss format
- **Input**: Time in seconds (float)
- **Output**: Formatted string (e.g., "05:23")
- **Note**: Currently defined but not actively used in main flow

**Dependencies**:
- Python standard library (`json`, `typing`)

**Interactions**:
- Called by `app.py` to parse AI-generated JSON
- Receives JSON string from AI analysis
- Returns structured Python data for UI rendering

---

### 5. **Caching Module** (`utils/cache.py`)

**Purpose**: Provide persistent, file-based caching system

**Responsibilities**:
- Store transcripts and analysis results on disk
- Retrieve cached data with TTL (Time To Live) validation
- Manage cache file organization
- Provide cache statistics and cleanup utilities

**Key Functions**:

#### `get_cache_file(cache_type: str, key: str) -> Path`
- **Purpose**: Generate cache file path
- **Input**: 
  - `cache_type`: 'transcript' or 'analysis'
  - `key`: Video ID (sanitized for filename)
- **Output**: Path object to cache file
- **Logic**: Creates filename like `transcript_VIDEO_ID.json` or `analysis_VIDEO_ID.json`
- **Storage**: Files stored in `.cache/` directory

#### `load_from_cache(cache_type: str, key: str, ttl: int) -> Optional[Any]`
- **Purpose**: Load cached data if valid
- **Input**:
  - `cache_type`: 'transcript' or 'analysis'
  - `key`: Video ID
  - `ttl`: Time to live in seconds
- **Output**: Cached data if valid, `None` if expired/missing
- **Logic**:
  1. Checks if cache file exists
  2. Loads JSON data
  3. Validates timestamp against TTL
  4. Returns data if valid, deletes file if expired
  5. Handles corrupted files gracefully
- **TTL Behavior**: 
  - Transcripts: 3600 seconds (1 hour)
  - Analysis: 86400 seconds (24 hours)

#### `save_to_cache(cache_type: str, key: str, data: Any) -> None`
- **Purpose**: Save data to cache file
- **Input**:
  - `cache_type`: 'transcript' or 'analysis'
  - `key`: Video ID
  - `data`: Any serializable data
- **Logic**:
  1. Creates cache data structure with timestamp
  2. Writes JSON to file
  3. Handles write errors silently (doesn't break app)
- **Storage Format**:
  ```json
  {
    "timestamp": 1234567890.123,
    "data": <actual cached data>
  }
  ```

#### `clear_cache(cache_type: Optional[str] = None) -> None`
- **Purpose**: Delete cache files
- **Input**: Optional cache type filter
- **Logic**: Deletes matching cache files

#### `get_cache_size() -> dict`
- **Purpose**: Get cache statistics
- **Output**: Dictionary with file counts and total size

**Dependencies**:
- Python standard library (`os`, `json`, `time`, `pathlib`)

**Interactions**:
- Called by `app.py` caching wrapper functions
- Used before external API calls (transcript, OpenAI)
- Used after successful API calls to persist results
- Provides persistence across app restarts (unlike Streamlit's in-memory cache)

---

## üîÑ Data Flow Diagram

### Complete Request Flow

```
1. USER INPUT
   ‚îî‚îÄ> User enters YouTube URL in Streamlit UI
       ‚îî‚îÄ> app.py receives URL string

2. URL PROCESSING
   ‚îî‚îÄ> app.py calls extract_video_id(url)
       ‚îî‚îÄ> utils/transcript.py extracts video ID
           ‚îî‚îÄ> Returns: video_id (string)

3. TRANSCRIPT CACHING CHECK
   ‚îî‚îÄ> app.py calls get_cached_transcript(video_id)
       ‚îú‚îÄ> Checks Streamlit cache (@st.cache_data)
       ‚îî‚îÄ> If miss: Checks file cache (utils/cache.py)
           ‚îú‚îÄ> If hit: Returns cached transcript
           ‚îî‚îÄ> If miss: Proceeds to fetch

4. TRANSCRIPT FETCHING
   ‚îî‚îÄ> app.py calls get_transcript(video_id)
       ‚îî‚îÄ> utils/transcript.py
           ‚îú‚îÄ> Calls YouTubeTranscriptApi.fetch()
           ‚îú‚îÄ> Processes transcript data
           ‚îî‚îÄ> Returns: transcript_text (string) or error_message

5. TRANSCRIPT CACHING STORAGE
   ‚îî‚îÄ> app.py saves transcript to cache
       ‚îú‚îÄ> Streamlit cache (automatic via @st.cache_data)
       ‚îî‚îÄ> File cache (utils/cache.py - save_to_cache())

6. AI ANALYSIS CACHING CHECK
   ‚îî‚îÄ> app.py calls get_cached_analysis(video_id, transcript)
       ‚îú‚îÄ> Checks Streamlit cache (@st.cache_data)
       ‚îî‚îÄ> If miss: Checks file cache (utils/cache.py)
           ‚îú‚îÄ> If hit: Returns cached (actions, summary)
           ‚îî‚îÄ> If miss: Proceeds to analyze

7. AI ANALYSIS
   ‚îî‚îÄ> app.py calls extract_actions_and_summary(transcript)
       ‚îî‚îÄ> utils/openai_api.py
           ‚îú‚îÄ> Truncates transcript (10k chars for actions, 4k for summary)
           ‚îú‚îÄ> API Call 1: Action extraction (JSON mode)
           ‚îÇ   ‚îî‚îÄ> Returns: actions_json_string
           ‚îî‚îÄ> API Call 2: Summary generation (text mode)
               ‚îî‚îÄ> Returns: summary_string
           ‚îî‚îÄ> Returns: (actions_json_string, summary_string)

8. ANALYSIS CACHING STORAGE
   ‚îî‚îÄ> app.py saves analysis to cache
       ‚îú‚îÄ> Streamlit cache (automatic via @st.cache_data)
       ‚îî‚îÄ> File cache (utils/cache.py - save_to_cache())

9. FORMATTING
   ‚îî‚îÄ> app.py calls parse_actions_json(actions_json_string)
       ‚îî‚îÄ> utils/format.py
           ‚îú‚îÄ> Parses JSON string
           ‚îú‚îÄ> Extracts steps array
           ‚îî‚îÄ> Returns: List[Dict] of steps

10. UI RENDERING
    ‚îî‚îÄ> app.py renders results
        ‚îú‚îÄ> Metrics (video ID, step count, word count)
        ‚îú‚îÄ> Summary card (styled HTML)
        ‚îú‚îÄ> Tools section (if tools found)
        ‚îî‚îÄ> Actionable steps (numbered cards with timestamps, code, tool context)
```

---

## üóÇÔ∏è File Structure & Dependencies

```
VidToDo/
‚îÇ
‚îú‚îÄ‚îÄ app.py                          # Main application entry point
‚îÇ   ‚îú‚îÄ‚îÄ Imports: streamlit, utils modules
‚îÇ   ‚îú‚îÄ‚îÄ UI Components: Headers, inputs, buttons, displays
‚îÇ   ‚îú‚îÄ‚îÄ Caching Wrappers: get_cached_transcript, get_cached_analysis
‚îÇ   ‚îî‚îÄ‚îÄ Main Flow: URL ‚Üí Video ID ‚Üí Transcript ‚Üí Analysis ‚Üí Display
‚îÇ
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                 # Package initialization
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ transcript.py               # YouTube transcript extraction
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ extract_video_id()     # URL parsing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ get_transcript()        # Transcript fetching
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Dependencies: youtube-transcript-api
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ openai_api.py               # AI analysis integration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ get_openai_api_key()   # Key retrieval
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ get_openai_client()     # Client initialization
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ extract_actions_and_summary()  # Main analysis function
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Dependencies: openai, python-dotenv, streamlit (for secrets)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ format.py                   # JSON parsing and formatting
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ parse_actions_json()    # Parse AI JSON response
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ format_timestamp()      # Time formatting utility
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Dependencies: json (stdlib)
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ cache.py                    # Persistent file-based caching
‚îÇ       ‚îú‚îÄ‚îÄ get_cache_file()        # Path generation
‚îÇ       ‚îú‚îÄ‚îÄ load_from_cache()      # Cache retrieval with TTL
‚îÇ       ‚îú‚îÄ‚îÄ save_to_cache()         # Cache storage
‚îÇ       ‚îú‚îÄ‚îÄ clear_cache()           # Cache cleanup
‚îÇ       ‚îú‚îÄ‚îÄ get_cache_size()        # Cache statistics
‚îÇ       ‚îî‚îÄ‚îÄ Dependencies: os, json, time, pathlib (stdlib)
‚îÇ
‚îú‚îÄ‚îÄ .cache/                         # Cache directory (auto-created)
‚îÇ   ‚îú‚îÄ‚îÄ transcript_VIDEO_ID.json    # Cached transcripts
‚îÇ   ‚îî‚îÄ‚îÄ analysis_VIDEO_ID.json      # Cached analysis results
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt                 # Python dependencies
‚îÇ   ‚îú‚îÄ‚îÄ streamlit                   # Web framework
‚îÇ   ‚îú‚îÄ‚îÄ openai                      # OpenAI API client
‚îÇ   ‚îú‚îÄ‚îÄ youtube-transcript-api      # YouTube transcript extraction
‚îÇ   ‚îú‚îÄ‚îÄ yt-dlp                      # YouTube downloader (future use)
‚îÇ   ‚îú‚îÄ‚îÄ whisper                     # Speech-to-text (future use)
‚îÇ   ‚îî‚îÄ‚îÄ python-dotenv               # Environment variable management
‚îÇ
‚îú‚îÄ‚îÄ .env                            # Environment variables (local)
‚îÇ   ‚îî‚îÄ‚îÄ OPENAI_API_KEY=sk-...       # API key for local development
‚îÇ
‚îî‚îÄ‚îÄ README.md                        # Project documentation
```

---

## üîå External Dependencies & APIs

### 1. **YouTube Transcript API** (via `youtube-transcript-api`)
- **Purpose**: Fetch video transcripts/captions
- **Interaction**: Called by `utils/transcript.py`
- **Data Flow**: Video ID ‚Üí Transcript text
- **Error Handling**: Comprehensive error messages for various failure modes
- **Language Support**: French (primary), English (fallback)

### 2. **OpenAI GPT-4o-mini API** (via `openai` library)
- **Purpose**: AI-powered analysis of transcripts
- **Interaction**: Called by `utils/openai_api.py`
- **Data Flow**: Transcript text ‚Üí JSON actions + text summary
- **API Calls**: Two separate calls per analysis
  - Action extraction (JSON mode)
  - Summary generation (text mode)
- **Authentication**: API key from Streamlit secrets or `.env` file

### 3. **Streamlit Framework**
- **Purpose**: Web application framework
- **Features Used**:
  - UI components (text inputs, buttons, containers)
  - Caching (`@st.cache_data`)
  - Secrets management (`st.secrets`)
  - Custom CSS styling
  - Session state management

---

## üíæ Caching Strategy

### Dual-Layer Caching System

**Layer 1: Streamlit In-Memory Cache**
- **Mechanism**: `@st.cache_data` decorator
- **Scope**: Application session
- **TTL**: 
  - Transcripts: 3600 seconds (1 hour)
  - Analysis: 86400 seconds (24 hours)
- **Advantage**: Fast, no I/O
- **Limitation**: Lost on app restart

**Layer 2: File-Based Persistent Cache**
- **Mechanism**: JSON files in `.cache/` directory
- **Scope**: Persistent across app restarts
- **TTL**: Same as Streamlit cache
- **Advantage**: Survives restarts, reduces API calls
- **Storage**: 
  - Format: `{timestamp: float, data: Any}`
  - Files: `transcript_VIDEO_ID.json`, `analysis_VIDEO_ID.json`

**Cache Flow**:
1. Check Streamlit cache first (fastest)
2. If miss, check file cache (persistent)
3. If miss, fetch from API
4. Save to both caches after successful fetch

---

## üîê Security & Configuration

### API Key Management

**Local Development**:
- Uses `.env` file with `OPENAI_API_KEY`
- Loaded via `python-dotenv` in `openai_api.py`

**Cloud Deployment (Streamlit Cloud)**:
- Uses `st.secrets["OPENAI_API_KEY"]`
- Configured in Streamlit Cloud dashboard
- Falls back to environment variable if secrets unavailable

**Priority Order**:
1. Streamlit secrets (cloud)
2. Environment variable (local)

---

## üé® UI Component Structure

### Main Components (app.py)

1. **Header Section**
   - Title: "üé¨ YouTube Action Extractor"
   - Subtitle: Description text
   - Custom CSS styling

2. **Input Section**
   - Text input for YouTube URL
   - Info box with tips
   - Analyze button

3. **Results Section** (conditional rendering)
   - **Metrics Row**: Video ID, Step count, Word count
   - **Summary Card**: Styled gradient card with bullet points
   - **Tools Section**: Expandable cards for each tool mentioned
   - **Steps Section**: Numbered cards with:
     - Timestamp (code-styled)
     - Action description
     - Tool context (if applicable)
     - Code snippets (if available)

4. **Sidebar**
   - About section
   - Features list
   - Privacy information

---

## üîÑ Error Handling Flow

### Transcript Errors
```
get_transcript() ‚Üí Error Detection
‚îú‚îÄ> TranscriptsDisabled ‚Üí User-friendly message
‚îú‚îÄ> NoTranscriptFound ‚Üí Helpful suggestions
‚îú‚îÄ> VideoUnavailable ‚Üí URL validation message
‚îú‚îÄ> IpBlocked/RequestBlocked ‚Üí Detailed troubleshooting guide
‚îî‚îÄ> Generic Exception ‚Üí Error message with context
```

### AI Analysis Errors
```
extract_actions_and_summary() ‚Üí Error Detection
‚îú‚îÄ> API Key Missing ‚Üí ValueError with setup instructions
‚îú‚îÄ> API Call Failure ‚Üí Exception with error details
‚îî‚îÄ> JSON Parse Failure ‚Üí Handled in format.py (returns empty list)
```

### Cache Errors
```
load_from_cache() ‚Üí Error Handling
‚îú‚îÄ> File Not Found ‚Üí Returns None (cache miss)
‚îú‚îÄ> Corrupted JSON ‚Üí Deletes file, returns None
‚îú‚îÄ> Expired TTL ‚Üí Deletes file, returns None
‚îî‚îÄ> Write Failure ‚Üí Silent failure (doesn't break app)
```

---

## üìä Data Structures

### Transcript Data
- **Type**: `str`
- **Content**: Plain text transcript from YouTube
- **Source**: YouTube Transcript API
- **Storage**: Cached as string in both cache layers

### Actions JSON Structure
```json
{
  "steps": [
    {
      "step": "Action description",
      "timestamp": "mm:ss",
      "code": "optional code snippet",
      "tool_context": "optional tool explanation"
    }
  ],
  "tools": [
    {
      "name": "Tool name",
      "timestamp": "mm:ss",
      "purpose": "Why tool is used",
      "context": "What aspect is explained",
      "usage": "How it fits in workflow"
    }
  ]
}
```

### Summary Data
- **Type**: `str`
- **Format**: 3 bullet points, max 120 words
- **Content**: High-level video overview

### Cache File Structure
```json
{
  "timestamp": 1234567890.123,
  "data": <actual cached data (transcript string or [actions, summary] tuple)>
}
```

---

## üöÄ Execution Flow Summary

1. **User Interaction**: User enters YouTube URL and clicks "Analyze"
2. **URL Processing**: Extract video ID from URL
3. **Cache Check**: Check both cache layers for transcript
4. **Transcript Fetch**: If cache miss, fetch from YouTube API
5. **Cache Store**: Save transcript to both cache layers
6. **Analysis Cache Check**: Check both cache layers for analysis
7. **AI Analysis**: If cache miss, call OpenAI API (2 calls)
8. **Cache Store**: Save analysis to both cache layers
9. **Formatting**: Parse JSON actions into structured data
10. **Rendering**: Display all results in styled UI components

---

## üîÆ Future Architecture Considerations

### Potential Enhancements (from README)
- **Whisper Integration**: Fallback for videos without transcripts
  - Would add: `utils/whisper_fallback.py`
  - Would use: `yt-dlp` to download audio, `whisper` to transcribe
- **Export Functionality**: Export to Markdown/Notion/TXT
  - Would add: `utils/export.py`
- **Playlist Support**: Process multiple videos
  - Would modify: `app.py` to handle multiple video IDs
  - Would add: Batch processing logic

---

## üìù Key Design Patterns

1. **Separation of Concerns**: Each module has a single, clear responsibility
2. **Dual Caching**: Fast in-memory + persistent file-based caching
3. **Error Resilience**: Comprehensive error handling at each layer
4. **Modularity**: Utils modules are independent and testable
5. **Configuration Flexibility**: Supports both local (.env) and cloud (secrets) configs
6. **Progressive Enhancement**: Cache-first approach reduces API calls

---

This architecture document provides a comprehensive overview of how each component interacts within the VidToDo system. Use this information to generate visual diagrams, flowcharts, or component interaction diagrams.

